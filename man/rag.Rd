% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rag.R
\name{rag}
\alias{rag}
\title{Retrieval-augmented Generation (RAG)}
\usage{
rag(
  text = NULL,
  path = NULL,
  prompt = "You are an expert at extracting themes across many texts",
  query,
  response_mode = c("accumulate", "compact", "refine", "simple_summarize",
    "tree_summarize"),
  similarity_top_k = 5,
  keep_in_env = TRUE,
  envir = 1,
  progress = TRUE
)
}
\arguments{
\item{text}{Character vector or list.
Text in a vector or list data format.
\code{path} will override input into \code{text}
Defaults to \code{NULL}}

\item{path}{Character.
Path to .pdfs stored locally on your computer.
Defaults to \code{NULL}}

\item{prompt}{Character (length = 1).
Prompt to feed into TinyLLAMA.
Defaults to \code{"You are an expert at extracting emotional themes across many texts"}}

\item{query}{Character.
The query you'd like to know from the documents.
Required with no default}

\item{response_mode}{Character (length = 1).
Different responses generated from the model.
See documentation \href{https://docs.llamaindex.ai/en/stable/module_guides/deploying/query_engine/response_modes.html}{here}

Defaults to \code{"tree_summarize"}}

\item{similarity_top_k}{Numeric (length = 1).
Retrieves most representative texts given the \code{query}.
Larger values will provide a more comprehensive response but at
the cost of computational efficiency; small values will provide
a more focused response at the cost of comprehensiveness.
Defaults to \code{5}.

Values will vary based on number of texts but some suggested values might be:

\describe{

\item{40-60 ---}{Comprehensive search across all texts}

\item{20-40 ---}{Exploratory with good trade-off between comprehensive and speed}

\item{5-15 ---}{Focused search that should give generally good results}

}

These values depend on the number and quality of texts. Adjust as necessary}

\item{keep_in_env}{Boolean (length = 1).
Whether the classifier should be kept in your global environment.
Defaults to \code{TRUE}.
By keeping the classifier in your environment, you can skip
re-loading the classifier every time you run this function.
\code{TRUE} is recommended}

\item{envir}{Numeric (length = 1).
Environment for the classifier to be saved for repeated use.
Defaults to the global environment}

\item{progress}{Boolean (length = 1).
Whether progress should be displayed.
Defaults to \code{TRUE}}
}
\value{
Returns response from TinyLLAMA
}
\description{
Performs retrieval-augmented generation using {llama-index}

Currently limited to the TinyLLAMA model
}
\examples{
# Load data
data(neo_ipip_extraversion)

# Example text
text <- neo_ipip_extraversion$friendliness[1:5]

\dontrun{
rag(
 text = text,
 query = "What themes are prevelant across the text?",
 response_mode = "tree_summarize",
 similarity_top_k = 5
)}

}
\author{
Alexander P. Christensen <alexpaulchristensen@gmail.com>
}
